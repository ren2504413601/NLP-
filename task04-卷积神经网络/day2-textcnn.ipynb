{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## textcnn\n",
    "将卷积神经网络CNN应用到文本分类任务，利用多个不同size的kernel来提取句子中的关键信息（类似于多窗口大小的ngram），从而能够更好地捕捉局部相关性。\n",
    "\n",
    "具体过程如下：\n",
    "![](textcnn.png)\n",
    "![](textcnn_model.png)\n",
    "**参考：**https://www.cnblogs.com/bymo/p/9675654.html\n",
    "\n",
    "**文本分类问题综述:**https://zhuanlan.zhihu.com/p/25928551"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.keras 实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-16 20:40:38.710854: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-16 20:40:38.788093: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-16 20:40:39.287633: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/renlei/TensorRT-8.4.1.5/lib:/usr/local/cuda-11.6/lib64:\n",
      "2023-12-16 20:40:39.287682: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/renlei/TensorRT-8.4.1.5/lib:/usr/local/cuda-11.6/lib64:\n",
      "2023-12-16 20:40:39.287686: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import tensorflow as tf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.layers import Conv1D, MaxPool1D, Dense, Flatten, concatenate, Embedding\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "\n",
    "def textcnn(max_sequence_length, max_token_num, embedding_dim, output_dim, model_img_path=None, embedding_matrix=None):\n",
    "    \"\"\" TextCNN: 1. embedding layers, 2.convolution layer, 3.max-pooling, 4.softmax layer. \"\"\"\n",
    "    x_input = Input(shape=(max_sequence_length,))\n",
    "    logging.info(\"x_input.shape: %s\" % str(x_input.shape))  # (?, 60)\n",
    "\n",
    "    if embedding_matrix is None:\n",
    "        x_emb = Embedding(input_dim=max_token_num, output_dim=embedding_dim, input_length=max_sequence_length)(x_input)\n",
    "    else:\n",
    "        x_emb = Embedding(input_dim=max_token_num, output_dim=embedding_dim, input_length=max_sequence_length,\n",
    "                          weights=[embedding_matrix], trainable=True)(x_input)\n",
    "    logging.info(\"x_emb.shape: %s\" % str(x_emb.shape))  # (?, 60, 300)\n",
    "\n",
    "    pool_output = []\n",
    "    kernel_sizes = [2, 3, 4] \n",
    "    for kernel_size in kernel_sizes:\n",
    "        c = Conv1D(filters=2, kernel_size=kernel_size, strides=1)(x_emb)\n",
    "        p = MaxPool1D(pool_size=int(c.shape[1]))(c)\n",
    "        pool_output.append(p)\n",
    "        logging.info(\"kernel_size: %s \\t c.shape: %s \\t p.shape: %s\" % (kernel_size, str(c.shape), str(p.shape)))\n",
    "    pool_output = concatenate([p for p in pool_output])\n",
    "    logging.info(\"pool_output.shape: %s\" % str(pool_output.shape))  # (?, 1, 6)\n",
    "\n",
    "    x_flatten = Flatten()(pool_output)  # (?, 6)\n",
    "    y = Dense(output_dim, activation='softmax')(x_flatten)  # (?, 2)\n",
    "    logging.info(\"y.shape: %s \\n\" % str(y.shape))\n",
    "\n",
    "    model = Model([x_input], outputs=[y])\n",
    "    if model_img_path:\n",
    "        plot_model(model, to_file=model_img_path, show_shapes=True, show_layer_names=False)\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 384)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 384, 3)       3072        ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 383, 2)       14          ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 382, 2)       20          ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 381, 2)       26          ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 1, 2)         0           ['conv1d[0][0]']                 \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 1, 2)        0           ['conv1d_1[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 1, 2)        0           ['conv1d_2[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 1, 6)         0           ['max_pooling1d[0][0]',          \n",
      "                                                                  'max_pooling1d_1[0][0]',        \n",
      "                                                                  'max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 6)            0           ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 3)            21          ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,153\n",
      "Trainable params: 3,153\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-16 20:40:39.860716: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-16 20:40:39.881351: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-16 20:40:39.881551: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-16 20:40:39.882124: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-16 20:40:39.882893: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-16 20:40:39.882997: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-16 20:40:39.883067: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-16 20:40:40.212167: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-16 20:40:40.212295: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-16 20:40:40.212367: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-16 20:40:40.212429: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6042 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.functional.Functional at 0x7f83445aa510>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textcnn(384, 1024, 3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f9697a2dd5b2151782a3f86c429a17173d5841c8767147afef20cb4c5e7a0764"
  },
  "kernelspec": {
   "display_name": "tensorflow1_15_py37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
