{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XOR\n",
    "**异或，英文为exclusive OR，缩写成xor。异或（xor）是一个数学运算符**\n",
    "## 1、感知机模型\n",
    "感知机模型可以简单的理解为单层的神经网络。感知机接收多个输入信号，输出一个信号。下图展示了一个简单的两个输入信号的感知机模型\n",
    "![](感知机.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2、异或运算\n",
    "异或操作直观来说就是如果两个输入的符号相同时（同为正或者同为负）则输出0，否则（一个正一个负）输出为1。\n",
    "\n",
    "数学逻辑语言可以表示为：$a \\oplus b=(\\neg a \\land b)\\lor(a \\land \\neg b)$\n",
    "\n",
    "其中$\\oplus$表示异或算子，$\\neg$表示非（逆）运算，即当$a=1$时，$\\neg a=0$；而$a=0$时，$\\neg a=1$。$\\land$和$\\lor$分别表示求交集和并集运算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然而，值的注意的是，感知机是无法模拟异或运算的。这在1969被证明，具体可以了解书籍 Perceptrons:An Introduction to Computational Geometry\n",
    "\n",
    "以下我们基于tensorflow说明这一事实，另外再加入了隐藏层之后，异或运算可以实现模拟。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3、基于tf的Perception模型和单隐藏层nn实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1、Perception 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_5427/855399435.py:8: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /tmp/ipykernel_5427/855399435.py:12: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /tmp/ipykernel_5427/855399435.py:20: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /tmp/ipykernel_5427/855399435.py:21: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /tmp/ipykernel_5427/855399435.py:23: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/renlei/miniconda3/envs/tensorflow1_15_py37/lib/python3.7/site-packages/ipykernel_launcher.py:4: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  after removing the cwd from sys.path.\n",
      "/home/renlei/miniconda3/envs/tensorflow1_15_py37/lib/python3.7/site-packages/ipykernel_launcher.py:5: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  \"\"\"\n",
      "2023-12-16 06:54:30.858335: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2023-12-16 06:54:30.884881: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-16 06:54:30.884958: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: NVIDIA GeForce RTX 3060 Ti major: 8 minor: 6 memoryClockRate(GHz): 1.71\n",
      "pciBusID: 0000:01:00.0\n",
      "2023-12-16 06:54:30.885049: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.0'; dlerror: libcudart.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/renlei/TensorRT-8.4.1.5/lib:/usr/local/cuda-11.6/lib64:\n",
      "2023-12-16 06:54:30.885097: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcublas.so.10.0'; dlerror: libcublas.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/renlei/TensorRT-8.4.1.5/lib:/usr/local/cuda-11.6/lib64:\n",
      "2023-12-16 06:54:30.885137: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcufft.so.10.0'; dlerror: libcufft.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/renlei/TensorRT-8.4.1.5/lib:/usr/local/cuda-11.6/lib64:\n",
      "2023-12-16 06:54:30.885175: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcurand.so.10.0'; dlerror: libcurand.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/renlei/TensorRT-8.4.1.5/lib:/usr/local/cuda-11.6/lib64:\n",
      "2023-12-16 06:54:30.885211: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusolver.so.10.0'; dlerror: libcusolver.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/renlei/TensorRT-8.4.1.5/lib:/usr/local/cuda-11.6/lib64:\n",
      "2023-12-16 06:54:30.885249: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusparse.so.10.0'; dlerror: libcusparse.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/renlei/TensorRT-8.4.1.5/lib:/usr/local/cuda-11.6/lib64:\n",
      "2023-12-16 06:54:30.885288: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/renlei/TensorRT-8.4.1.5/lib:/usr/local/cuda-11.6/lib64:\n",
      "2023-12-16 06:54:30.885292: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1641] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-12-16 06:54:30.886038: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
      "2023-12-16 06:54:30.912355: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2496000000 Hz\n",
      "2023-12-16 06:54:30.913024: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3b1d860 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2023-12-16 06:54:30.913039: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2023-12-16 06:54:30.972109: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-16 06:54:30.972275: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4ad1860 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-12-16 06:54:30.972284: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3060 Ti, Compute Capability 8.6\n",
      "2023-12-16 06:54:30.972347: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-12-16 06:54:30.972351: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step0,nn loss is:1.7994823455810547\n",
      "step10,nn loss is:1.3787894248962402\n",
      "step20,nn loss is:1.0566428899765015\n",
      "step30,nn loss is:0.8285753130912781\n",
      "step40,nn loss is:0.6813265681266785\n",
      "step50,nn loss is:0.5945343971252441\n",
      "step60,nn loss is:0.5467054843902588\n",
      "step70,nn loss is:0.5201416015625\n",
      "step80,nn loss is:0.50311678647995\n",
      "step90,nn loss is:0.4893961250782013\n",
      "step100,nn loss is:0.47639942169189453\n",
      "step110,nn loss is:0.46337807178497314\n",
      "step120,nn loss is:0.4502507448196411\n",
      "step130,nn loss is:0.43708181381225586\n",
      "step140,nn loss is:0.4239281117916107\n",
      "step150,nn loss is:0.41082507371902466\n",
      "step160,nn loss is:0.3977985978126526\n",
      "step170,nn loss is:0.3848717510700226\n",
      "step180,nn loss is:0.37206578254699707\n",
      "step190,nn loss is:0.35940006375312805\n",
      "step200,nn loss is:0.3468928337097168\n",
      "step210,nn loss is:0.334975004196167\n",
      "step220,nn loss is:0.3241308629512787\n",
      "step230,nn loss is:0.3143948018550873\n",
      "step240,nn loss is:0.3057214915752411\n",
      "step250,nn loss is:0.29804137349128723\n",
      "step260,nn loss is:0.2912742495536804\n",
      "step270,nn loss is:0.2853374183177948\n",
      "step280,nn loss is:0.28015023469924927\n",
      "step290,nn loss is:0.275636225938797\n",
      "step300,nn loss is:0.2717234492301941\n",
      "step310,nn loss is:0.26834508776664734\n",
      "step320,nn loss is:0.26543936133384705\n",
      "step330,nn loss is:0.2629496157169342\n",
      "step340,nn loss is:0.260824590921402\n",
      "step350,nn loss is:0.2590175271034241\n",
      "step360,nn loss is:0.2574866712093353\n",
      "step370,nn loss is:0.25619468092918396\n",
      "step380,nn loss is:0.2551082968711853\n",
      "step390,nn loss is:0.25419822335243225\n",
      "step400,nn loss is:0.2534385919570923\n",
      "step410,nn loss is:0.2528069019317627\n",
      "step420,nn loss is:0.25228351354599\n",
      "step430,nn loss is:0.25185146927833557\n",
      "step440,nn loss is:0.2514960765838623\n",
      "step450,nn loss is:0.25120478868484497\n",
      "step460,nn loss is:0.2509669363498688\n",
      "step470,nn loss is:0.25077342987060547\n",
      "step480,nn loss is:0.25061655044555664\n",
      "step490,nn loss is:0.25048983097076416\n",
      "step500,nn loss is:0.2503878176212311\n",
      "step510,nn loss is:0.25030601024627686\n",
      "step520,nn loss is:0.25024062395095825\n",
      "step530,nn loss is:0.25018855929374695\n",
      "step540,nn loss is:0.25014728307724\n",
      "step550,nn loss is:0.2501146197319031\n",
      "step560,nn loss is:0.2500889003276825\n",
      "step570,nn loss is:0.250068724155426\n",
      "step580,nn loss is:0.25005292892456055\n",
      "step590,nn loss is:0.2500406503677368\n",
      "step600,nn loss is:0.25003108382225037\n",
      "step610,nn loss is:0.2500237226486206\n",
      "step620,nn loss is:0.25001800060272217\n",
      "step630,nn loss is:0.2500136196613312\n",
      "step640,nn loss is:0.25001028180122375\n",
      "step650,nn loss is:0.2500077486038208\n",
      "step660,nn loss is:0.2500058114528656\n",
      "step670,nn loss is:0.25000429153442383\n",
      "step680,nn loss is:0.2500031888484955\n",
      "step690,nn loss is:0.25000235438346863\n",
      "step700,nn loss is:0.2500017583370209\n",
      "step710,nn loss is:0.25000128149986267\n",
      "step720,nn loss is:0.2500009536743164\n",
      "step730,nn loss is:0.25000065565109253\n",
      "step740,nn loss is:0.2500005066394806\n",
      "step750,nn loss is:0.25000038743019104\n",
      "step760,nn loss is:0.2500002384185791\n",
      "step770,nn loss is:0.2500001788139343\n",
      "step780,nn loss is:0.25000011920928955\n",
      "step790,nn loss is:0.25000011920928955\n",
      "step800,nn loss is:0.25000008940696716\n",
      "step810,nn loss is:0.2500000596046448\n",
      "step820,nn loss is:0.25\n",
      "step830,nn loss is:0.2500000298023224\n",
      "step840,nn loss is:0.2500000298023224\n",
      "step850,nn loss is:0.25\n",
      "step860,nn loss is:0.25\n",
      "step870,nn loss is:0.25\n",
      "step880,nn loss is:0.25\n",
      "step890,nn loss is:0.25\n",
      "step900,nn loss is:0.25\n",
      "step910,nn loss is:0.25\n",
      "step920,nn loss is:0.25\n",
      "step930,nn loss is:0.25\n",
      "step940,nn loss is:0.25\n",
      "step950,nn loss is:0.25\n",
      "step960,nn loss is:0.25\n",
      "step970,nn loss is:0.2499999850988388\n",
      "step980,nn loss is:0.25\n",
      "step990,nn loss is:0.25\n",
      "step1000,nn loss is:0.25\n",
      "step1010,nn loss is:0.2499999850988388\n",
      "step1020,nn loss is:0.25\n",
      "step1030,nn loss is:0.25\n",
      "step1040,nn loss is:0.25\n",
      "step1050,nn loss is:0.25\n",
      "step1060,nn loss is:0.25\n",
      "step1070,nn loss is:0.25\n",
      "step1080,nn loss is:0.25\n",
      "step1090,nn loss is:0.25\n",
      "step1100,nn loss is:0.25\n",
      "step1110,nn loss is:0.25\n",
      "step1120,nn loss is:0.25\n",
      "step1130,nn loss is:0.25\n",
      "step1140,nn loss is:0.25\n",
      "step1150,nn loss is:0.25\n",
      "step1160,nn loss is:0.25\n",
      "step1170,nn loss is:0.25\n",
      "step1180,nn loss is:0.25\n",
      "step1190,nn loss is:0.25\n",
      "step1200,nn loss is:0.25\n",
      "step1210,nn loss is:0.25\n",
      "step1220,nn loss is:0.25\n",
      "step1230,nn loss is:0.25\n",
      "step1240,nn loss is:0.25\n",
      "step1250,nn loss is:0.25\n",
      "step1260,nn loss is:0.25\n",
      "step1270,nn loss is:0.25\n",
      "step1280,nn loss is:0.25\n",
      "step1290,nn loss is:0.25\n",
      "step1300,nn loss is:0.25\n",
      "step1310,nn loss is:0.25\n",
      "step1320,nn loss is:0.25\n",
      "step1330,nn loss is:0.25\n",
      "step1340,nn loss is:0.25\n",
      "step1350,nn loss is:0.25\n",
      "step1360,nn loss is:0.25\n",
      "step1370,nn loss is:0.2500000298023224\n",
      "step1380,nn loss is:0.2500000298023224\n",
      "step1390,nn loss is:0.2500000298023224\n",
      "step1400,nn loss is:0.2500000298023224\n",
      "step1410,nn loss is:0.2500000298023224\n",
      "step1420,nn loss is:0.2500000298023224\n",
      "step1430,nn loss is:0.2500000298023224\n",
      "step1440,nn loss is:0.2500000298023224\n",
      "step1450,nn loss is:0.2500000298023224\n",
      "step1460,nn loss is:0.2500000298023224\n",
      "step1470,nn loss is:0.25\n",
      "step1480,nn loss is:0.25\n",
      "step1490,nn loss is:0.25\n",
      "step1500,nn loss is:0.25\n",
      "step1510,nn loss is:0.25\n",
      "step1520,nn loss is:0.25\n",
      "step1530,nn loss is:0.25\n",
      "step1540,nn loss is:0.25\n",
      "step1550,nn loss is:0.25\n",
      "step1560,nn loss is:0.25\n",
      "step1570,nn loss is:0.25\n",
      "step1580,nn loss is:0.25\n",
      "step1590,nn loss is:0.25\n",
      "step1600,nn loss is:0.25\n",
      "step1610,nn loss is:0.25\n",
      "step1620,nn loss is:0.25\n",
      "step1630,nn loss is:0.25\n",
      "step1640,nn loss is:0.25\n",
      "step1650,nn loss is:0.25\n",
      "step1660,nn loss is:0.25\n",
      "step1670,nn loss is:0.25\n",
      "step1680,nn loss is:0.25\n",
      "step1690,nn loss is:0.25\n",
      "step1700,nn loss is:0.25\n",
      "step1710,nn loss is:0.25\n",
      "step1720,nn loss is:0.25\n",
      "step1730,nn loss is:0.25\n",
      "step1740,nn loss is:0.25\n",
      "step1750,nn loss is:0.25\n",
      "step1760,nn loss is:0.25\n",
      "step1770,nn loss is:0.25\n",
      "step1780,nn loss is:0.25\n",
      "step1790,nn loss is:0.25\n",
      "step1800,nn loss is:0.25\n",
      "step1810,nn loss is:0.25\n",
      "step1820,nn loss is:0.25\n",
      "step1830,nn loss is:0.25\n",
      "step1840,nn loss is:0.25\n",
      "step1850,nn loss is:0.25\n",
      "step1860,nn loss is:0.25\n",
      "step1870,nn loss is:0.25\n",
      "step1880,nn loss is:0.25\n",
      "step1890,nn loss is:0.25\n",
      "step1900,nn loss is:0.25\n",
      "step1910,nn loss is:0.25\n",
      "step1920,nn loss is:0.25\n",
      "step1930,nn loss is:0.25\n",
      "step1940,nn loss is:0.25\n",
      "step1950,nn loss is:0.25\n",
      "step1960,nn loss is:0.25\n",
      "step1970,nn loss is:0.25\n",
      "step1980,nn loss is:0.25\n",
      "step1990,nn loss is:0.25\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "# init data\n",
    "x_data=np.array([[1,1],[1,0],[0,1],[0,0]],dtype=np.int)\n",
    "y_data=np.array([[0],[1],[1],[0]],dtype=np.int)\n",
    "\n",
    "# define tf placeholder\n",
    "x=tf.placeholder(tf.float32,[None,2],name='x-input')\n",
    "y=tf.placeholder(tf.float32,[None,1],name='y-input')\n",
    "\n",
    "# define parameters\n",
    "w=tf.Variable(tf.random_normal([2,1]))\n",
    "b=tf.Variable([0.1])\n",
    "\n",
    "# model init\n",
    "out=tf.nn.relu(tf.matmul(x,w)+b)\n",
    "\n",
    "loss=tf.reduce_mean(tf.square(y-out))# 含隐藏层的网络\n",
    "\n",
    "opt=tf.train.AdamOptimizer(0.01).minimize(loss)\n",
    "init=tf.global_variables_initializer()\n",
    "fd={x:x_data,y:y_data}\n",
    "sess=tf.Session()\n",
    "sess.run(init)\n",
    "for i in range(2000):\n",
    "    _,per_loss=sess.run([opt,loss],feed_dict=fd)\n",
    "    if (i%10)==0:# 10次输出一下结果\n",
    "        print('step{},nn loss is:{}'.format(i,per_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2、单隐藏层的nn模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/renlei/miniconda3/envs/tensorflow1_15_py37/lib/python3.7/site-packages/ipykernel_launcher.py:4: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  after removing the cwd from sys.path.\n",
      "/home/renlei/miniconda3/envs/tensorflow1_15_py37/lib/python3.7/site-packages/ipykernel_launcher.py:5: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  \"\"\"\n",
      "2023-12-16 06:55:57.569728: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-12-16 06:55:57.569748: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step0,nn loss is:0.46756458282470703\n",
      "step10,nn loss is:0.3277129530906677\n",
      "step20,nn loss is:0.2693403959274292\n",
      "step30,nn loss is:0.2584536671638489\n",
      "step40,nn loss is:0.25852057337760925\n",
      "step50,nn loss is:0.25495150685310364\n",
      "step60,nn loss is:0.2536029517650604\n",
      "step70,nn loss is:0.2527908980846405\n",
      "step80,nn loss is:0.2520788311958313\n",
      "step90,nn loss is:0.2516231834888458\n",
      "step100,nn loss is:0.2512795031070709\n",
      "step110,nn loss is:0.25101426243782043\n",
      "step120,nn loss is:0.25081366300582886\n",
      "step130,nn loss is:0.2506573498249054\n",
      "step140,nn loss is:0.25053495168685913\n",
      "step150,nn loss is:0.2504381537437439\n",
      "step160,nn loss is:0.25036072731018066\n",
      "step170,nn loss is:0.250298410654068\n",
      "step180,nn loss is:0.2502478361129761\n",
      "step190,nn loss is:0.25020653009414673\n",
      "step200,nn loss is:0.25017261505126953\n",
      "step210,nn loss is:0.2501445710659027\n",
      "step220,nn loss is:0.2501213252544403\n",
      "step230,nn loss is:0.2501019239425659\n",
      "step240,nn loss is:0.250085711479187\n",
      "step250,nn loss is:0.2500721216201782\n",
      "step260,nn loss is:0.25006064772605896\n",
      "step270,nn loss is:0.25005102157592773\n",
      "step280,nn loss is:0.2500428855419159\n",
      "step290,nn loss is:0.2500360310077667\n",
      "step300,nn loss is:0.2500302195549011\n",
      "step310,nn loss is:0.25002533197402954\n",
      "step320,nn loss is:0.25002115964889526\n",
      "step330,nn loss is:0.2500176727771759\n",
      "step340,nn loss is:0.2500147521495819\n",
      "step350,nn loss is:0.25001224875450134\n",
      "step360,nn loss is:0.2500101625919342\n",
      "step370,nn loss is:0.25000840425491333\n",
      "step380,nn loss is:0.25000694394111633\n",
      "step390,nn loss is:0.25000572204589844\n",
      "step400,nn loss is:0.25000470876693726\n",
      "step410,nn loss is:0.250003844499588\n",
      "step420,nn loss is:0.2500031292438507\n",
      "step430,nn loss is:0.25000256299972534\n",
      "step440,nn loss is:0.25000208616256714\n",
      "step450,nn loss is:0.2500016689300537\n",
      "step460,nn loss is:0.25000134110450745\n",
      "step470,nn loss is:0.25000107288360596\n",
      "step480,nn loss is:0.25000089406967163\n",
      "step490,nn loss is:0.2500006854534149\n",
      "step500,nn loss is:0.25000056624412537\n",
      "step510,nn loss is:0.2500004470348358\n",
      "step520,nn loss is:0.25000035762786865\n",
      "step530,nn loss is:0.2500002682209015\n",
      "step540,nn loss is:0.2500002086162567\n",
      "step550,nn loss is:0.25000014901161194\n",
      "step560,nn loss is:0.25000014901161194\n",
      "step570,nn loss is:0.25000011920928955\n",
      "step580,nn loss is:0.25000008940696716\n",
      "step590,nn loss is:0.2500000596046448\n",
      "step600,nn loss is:0.2500000596046448\n",
      "step610,nn loss is:0.2500000596046448\n",
      "step620,nn loss is:0.25\n",
      "step630,nn loss is:0.2500000298023224\n",
      "step640,nn loss is:0.2500000298023224\n",
      "step650,nn loss is:0.2500000298023224\n",
      "step660,nn loss is:0.25\n",
      "step670,nn loss is:0.2499999850988388\n",
      "step680,nn loss is:0.25\n",
      "step690,nn loss is:0.25\n",
      "step700,nn loss is:0.25\n",
      "step710,nn loss is:0.2499999850988388\n",
      "step720,nn loss is:0.25\n",
      "step730,nn loss is:0.25\n",
      "step740,nn loss is:0.25\n",
      "step750,nn loss is:0.25\n",
      "step760,nn loss is:0.25\n",
      "step770,nn loss is:0.25\n",
      "step780,nn loss is:0.25\n",
      "step790,nn loss is:0.25\n",
      "step800,nn loss is:0.25\n",
      "step810,nn loss is:0.25\n",
      "step820,nn loss is:0.2499999850988388\n",
      "step830,nn loss is:0.25\n",
      "step840,nn loss is:0.25\n",
      "step850,nn loss is:0.2499999850988388\n",
      "step860,nn loss is:0.25\n",
      "step870,nn loss is:0.25\n",
      "step880,nn loss is:0.25\n",
      "step890,nn loss is:0.25\n",
      "step900,nn loss is:0.2499999850988388\n",
      "step910,nn loss is:0.25\n",
      "step920,nn loss is:0.25\n",
      "step930,nn loss is:0.2499999850988388\n",
      "step940,nn loss is:0.25\n",
      "step950,nn loss is:0.25\n",
      "step960,nn loss is:0.2499999850988388\n",
      "step970,nn loss is:0.2499999850988388\n",
      "step980,nn loss is:0.25\n",
      "step990,nn loss is:0.2499999850988388\n",
      "step1000,nn loss is:0.25\n",
      "step1010,nn loss is:0.25\n",
      "step1020,nn loss is:0.2499999850988388\n",
      "step1030,nn loss is:0.25\n",
      "step1040,nn loss is:0.2499999850988388\n",
      "step1050,nn loss is:0.2499999850988388\n",
      "step1060,nn loss is:0.25\n",
      "step1070,nn loss is:0.25\n",
      "step1080,nn loss is:0.25\n",
      "step1090,nn loss is:0.2499999850988388\n",
      "step1100,nn loss is:0.25\n",
      "step1110,nn loss is:0.25\n",
      "step1120,nn loss is:0.25\n",
      "step1130,nn loss is:0.25\n",
      "step1140,nn loss is:0.25\n",
      "step1150,nn loss is:0.25\n",
      "step1160,nn loss is:0.25\n",
      "step1170,nn loss is:0.25\n",
      "step1180,nn loss is:0.25\n",
      "step1190,nn loss is:0.25\n",
      "step1200,nn loss is:0.25\n",
      "step1210,nn loss is:0.25\n",
      "step1220,nn loss is:0.25\n",
      "step1230,nn loss is:0.25\n",
      "step1240,nn loss is:0.25\n",
      "step1250,nn loss is:0.25\n",
      "step1260,nn loss is:0.25\n",
      "step1270,nn loss is:0.25\n",
      "step1280,nn loss is:0.25\n",
      "step1290,nn loss is:0.25\n",
      "step1300,nn loss is:0.25\n",
      "step1310,nn loss is:0.25\n",
      "step1320,nn loss is:0.25\n",
      "step1330,nn loss is:0.25\n",
      "step1340,nn loss is:0.25\n",
      "step1350,nn loss is:0.25\n",
      "step1360,nn loss is:0.25\n",
      "step1370,nn loss is:0.25\n",
      "step1380,nn loss is:0.25\n",
      "step1390,nn loss is:0.25\n",
      "step1400,nn loss is:0.25\n",
      "step1410,nn loss is:0.25\n",
      "step1420,nn loss is:0.25\n",
      "step1430,nn loss is:0.25\n",
      "step1440,nn loss is:0.25\n",
      "step1450,nn loss is:0.2499999850988388\n",
      "step1460,nn loss is:0.25\n",
      "step1470,nn loss is:0.25\n",
      "step1480,nn loss is:0.25\n",
      "step1490,nn loss is:0.25\n",
      "step1500,nn loss is:0.25\n",
      "step1510,nn loss is:0.2499999701976776\n",
      "step1520,nn loss is:0.25\n",
      "step1530,nn loss is:0.25\n",
      "step1540,nn loss is:0.2499999701976776\n",
      "step1550,nn loss is:0.2499999701976776\n",
      "step1560,nn loss is:0.2499999701976776\n",
      "step1570,nn loss is:0.2499999701976776\n",
      "step1580,nn loss is:0.2499999701976776\n",
      "step1590,nn loss is:0.25\n",
      "step1600,nn loss is:0.2499999701976776\n",
      "step1610,nn loss is:0.2499999701976776\n",
      "step1620,nn loss is:0.2499999701976776\n",
      "step1630,nn loss is:0.2499999701976776\n",
      "step1640,nn loss is:0.2499999701976776\n",
      "step1650,nn loss is:0.25\n",
      "step1660,nn loss is:0.2499999701976776\n",
      "step1670,nn loss is:0.2499999701976776\n",
      "step1680,nn loss is:0.2499999701976776\n",
      "step1690,nn loss is:0.2499999701976776\n",
      "step1700,nn loss is:0.2499999701976776\n",
      "step1710,nn loss is:0.25\n",
      "step1720,nn loss is:0.2499999701976776\n",
      "step1730,nn loss is:0.2499999701976776\n",
      "step1740,nn loss is:0.2499999701976776\n",
      "step1750,nn loss is:0.2499999701976776\n",
      "step1760,nn loss is:0.2499999701976776\n",
      "step1770,nn loss is:0.25\n",
      "step1780,nn loss is:0.2499999701976776\n",
      "step1790,nn loss is:0.2499999701976776\n",
      "step1800,nn loss is:0.2499999701976776\n",
      "step1810,nn loss is:0.2499999701976776\n",
      "step1820,nn loss is:0.2499999701976776\n",
      "step1830,nn loss is:0.25\n",
      "step1840,nn loss is:0.2499999701976776\n",
      "step1850,nn loss is:0.2499999701976776\n",
      "step1860,nn loss is:0.2499999701976776\n",
      "step1870,nn loss is:0.2499999701976776\n",
      "step1880,nn loss is:0.2499999701976776\n",
      "step1890,nn loss is:0.25\n",
      "step1900,nn loss is:0.2499999701976776\n",
      "step1910,nn loss is:0.2499999701976776\n",
      "step1920,nn loss is:0.2499999701976776\n",
      "step1930,nn loss is:0.2499999701976776\n",
      "step1940,nn loss is:0.2499999701976776\n",
      "step1950,nn loss is:0.25\n",
      "step1960,nn loss is:0.2499999701976776\n",
      "step1970,nn loss is:0.2499999701976776\n",
      "step1980,nn loss is:0.2499999701976776\n",
      "step1990,nn loss is:0.2499999701976776\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "# init data\n",
    "x_data=np.array([[1,1],[1,0],[0,1],[0,0]],dtype=np.int)\n",
    "y_data=np.array([[0],[1],[1],[0]],dtype=np.int)\n",
    "\n",
    "# define tf placeholder\n",
    "x=tf.placeholder(tf.float32,[None,2],name='x-input')\n",
    "y=tf.placeholder(tf.float32,[None,1],name='y-input')\n",
    "\n",
    "# define parameters\n",
    "w1=tf.Variable(tf.random_normal([2,2]))\n",
    "w2=tf.Variable(tf.random_normal([2,1]))\n",
    "b1=tf.Variable([0.1,0.1])\n",
    "b2=tf.Variable([0.1])\n",
    "\n",
    "# model init\n",
    "out1=tf.nn.relu(tf.matmul(x,w1)+b1)\n",
    "out2=tf.matmul(out1,w2)+b2\n",
    "\n",
    "\n",
    "loss=tf.reduce_mean(tf.square(y-out2))# 含隐藏层的网络\n",
    "\n",
    "\n",
    "opt=tf.train.AdamOptimizer(0.01).minimize(loss)\n",
    "init=tf.global_variables_initializer()\n",
    "fd={x:x_data,y:y_data}\n",
    "sess=tf.Session()\n",
    "sess.run(init)\n",
    "for i in range(2000):\n",
    "    _,nn_loss=sess.run([opt,loss],feed_dict=fd)\n",
    "    if (i%10)==0:# 10次输出一下结果\n",
    "        print('step{},nn loss is:{}'.format(i,nn_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**再附上tensorflow playground的结果：**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](perception.png)\n",
    "**明显看到，当没有隐藏层使用感知机来模拟异或操作效果比较差，损失函数取值表较大。**\n",
    "![](1_hidden.png)\n",
    "**使用含隐藏层的神经网络模型在合适的参数之下能很好的拟合异或操作，损失函数在很短时间之内接近0**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow1_15_py37",
   "language": "python",
   "name": "tensorflow1_15_py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
